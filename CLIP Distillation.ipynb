{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaee5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models import get_model\n",
    "from loaders import dataset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7290307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPDistill(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 # teacher\n",
    "                 teacher_dimension: int,\n",
    "                 teacher_model: nn.Module,\n",
    "                 # student\n",
    "                 student_dimension: int,\n",
    "                 student_model: nn.Module,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        \n",
    "        self.student_projection = nn.Parameter(torch.randn(student_dimension,embed_dim))\n",
    "        self.teacher_projection = nn.Parameter(torch.randn(teacher_dimension,embed_dim))\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))        \n",
    "\n",
    "  \n",
    "    #### What is this for?\n",
    "    \n",
    "#     def build_attention_mask(self):\n",
    "#         # lazily create causal attention mask, with full attention between the vision tokens\n",
    "#         # pytorch uses additive attention mask; fill with -inf\n",
    "#         mask = torch.empty(self.context_length, self.context_length)\n",
    "#         mask.fill_(float(\"-inf\"))\n",
    "#         mask.triu_(1)  # zero out the lower diagonal\n",
    "#         return mask\n",
    "    \n",
    "    def student_encoding(self, x):\n",
    "        return self.student(x) @ self.student_projection\n",
    "\n",
    "    \n",
    "    def teacher_encoding(self, x):\n",
    "        return self.teacher(x) @ self.teacher_projection\n",
    "            \n",
    "    def forward(self, x):\n",
    "        student_features = self.student_encoding(x)\n",
    "        teacher_features = self.teacher_encoding(x)\n",
    "\n",
    "        # normalized features\n",
    "        student_features = student_features / student_features.norm(dim=-1, keepdim=True)\n",
    "        teacher_features = teacher_features / teacher_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_student_emb = logit_scale * student_features @ teacher_features.t()\n",
    "        logits_per_teacher_emb = logits_per_student_emb.t()\n",
    "\n",
    "        # shape = [global_batch_size, global_batch_size]\n",
    "        return logits_per_teacher_emb, logits_per_student_emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5ac4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_distill_loss(logits_teacher,logits_student):\n",
    "    targets = torch.arange(batch_size)\n",
    "    ce_teacher = F.cross_entropy(logits_teacher,targets)\n",
    "    ce_student = F.cross_entropy(logits_student,targets)    \n",
    "    \n",
    "    return (ce_teacher + ce_student) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "acd98359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get loaders\n",
    "batch_size = 64\n",
    "train_loader,test_loader = dataset_loader('cifar', batch_size = batch_size,train_set_fraction = 1,validate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7bdbe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get models\n",
    "embed_dim = 512\n",
    "teacher_dim = 512\n",
    "student_dim = 512\n",
    "\n",
    "T = get_model('resnet18_cifar',load = True,load_path = 'cifar_teacher/model.pt',map_location = 'cpu',get_embedder = True)\n",
    "S = get_model('resnet18_cifar',load = False,get_embedder = True)\n",
    "\n",
    "clip = CLIPDistill(embed_dim,teacher_dim,T,student_dim,S)\n",
    "\n",
    "# Get Optimizer\n",
    "optimizer = torch.optim.Adam(clip.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be084981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2267, grad_fn=<DivBackward0>)\n",
      "tensor(4.8297, grad_fn=<DivBackward0>)\n",
      "tensor(4.7872, grad_fn=<DivBackward0>)\n",
      "tensor(4.4656, grad_fn=<DivBackward0>)\n",
      "tensor(4.0791, grad_fn=<DivBackward0>)\n",
      "tensor(3.9272, grad_fn=<DivBackward0>)\n",
      "tensor(3.9005, grad_fn=<DivBackward0>)\n",
      "tensor(3.5109, grad_fn=<DivBackward0>)\n",
      "tensor(3.4316, grad_fn=<DivBackward0>)\n",
      "tensor(3.2927, grad_fn=<DivBackward0>)\n",
      "tensor(3.1091, grad_fn=<DivBackward0>)\n",
      "tensor(2.8958, grad_fn=<DivBackward0>)\n",
      "tensor(2.9942, grad_fn=<DivBackward0>)\n",
      "tensor(2.6891, grad_fn=<DivBackward0>)\n",
      "tensor(2.6913, grad_fn=<DivBackward0>)\n",
      "tensor(2.5474, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "### Run the training loop\n",
    "epochs = range(10)\n",
    "for epoch in epochs:\n",
    "    \n",
    "    for data,_ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        teacher_logits,student_logits = clip(data)\n",
    "        loss = clip_distill_loss(teacher_logits,student_logits)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f81a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
